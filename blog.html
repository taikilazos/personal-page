<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - Taiki Papandreou</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <header class="header">
        <nav class="nav">
            <div class="nav-brand">
                <a href="index.html">Taiki Papandreou</a>
            </div>
            <ul class="nav-menu">
                <li><a href="index.html" class="nav-link">About</a></li>
                <li><a href="projects.html" class="nav-link">Projects</a></li>
                <li><a href="blog.html" class="nav-link active">Blog</a></li>
            </ul>
        </nav>
    </header>

    <main class="main">
        <section class="blog-hero">
            <div class="container">
                <h1 class="section-title">Blog</h1>
                <p class="blog-description">
                    Thoughts on technology, development, AI, and the occasional life update.
                </p>
            </div>
        </section>

        <section class="blog-posts">
            <div class="container">
                <div class="posts-container">
                    <article class="blog-post">
                        <div class="post-meta">
                            <span class="post-date">October 27, 2024</span>
                            <span class="post-category">AI & Machine Learning</span>
                        </div>
                        <h2 class="post-title">
                            <a href="blog/attention-transformers.html">Understanding Attention & Transformers</a>
                        </h2>
                        <p class="post-excerpt">
                            A deep dive into attention mechanisms and Transformer architecture—from the original attention mechanism 
                            to building a working model in PyTorch. Learn how modern AI systems like GPT and BERT work under the hood.
                        </p>
                        <a href="blog/attention-transformers.html" class="read-more">Read More →</a>
                    </article>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2024 Taiki Papandreou</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html> 